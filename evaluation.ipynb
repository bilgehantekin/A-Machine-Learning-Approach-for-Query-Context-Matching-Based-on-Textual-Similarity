{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# 0) Cross-Encoder modeli yÃ¼kle\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 1) Ham veriyi yÃ¼kle\n",
    "raw_train = pd.read_csv(\"wikiqa_train.csv\").reset_index(drop=True)\n",
    "raw_test  = pd.read_csv(\"wikiqa_test.csv\").reset_index(drop=True)\n",
    "\n",
    "# 2) CE skorlarÄ±nÄ± hesapla\n",
    "def compute_ce_scores(df):\n",
    "    scores = []\n",
    "    batch_size = 32\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"CE scoring\"):\n",
    "        batch = df.iloc[i : i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch[\"question\"].tolist(),\n",
    "            batch[\"answer\"].tolist(),\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            scores.extend(logits.squeeze(-1).cpu().tolist())\n",
    "    return scores\n",
    "\n",
    "# 3) CE skoru ekle\n",
    "feat_train = pd.read_csv(\"final_feature_set_train.csv\").reset_index(drop=True)\n",
    "feat_test  = pd.read_csv(\"final_feature_set_test.csv\").reset_index(drop=True)\n",
    "\n",
    "feat_train[\"ce_score\"] = compute_ce_scores(raw_train)\n",
    "feat_test[\"ce_score\"]  = compute_ce_scores(raw_test)\n",
    "\n",
    "# Etiketleri ayÄ±r\n",
    "X_train_meta = feat_train.drop(columns=[\"question_id\", \"label\"])\n",
    "y_train_meta = feat_train[\"label\"]\n",
    "X_test_meta = feat_test.drop(columns=[\"question_id\", \"label\", \"proba_meta\", \"pred_meta\"], errors='ignore')\n",
    "y_test_meta = feat_test[\"label\"].astype(int)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2) scale_pos_weight Hesapla\n",
    "# ----------------------------------------\n",
    "neg = (y_train_meta == 0).sum()\n",
    "pos = (y_train_meta == 1).sum()\n",
    "scale_pos = neg / pos\n",
    "print(f\"ðŸ”¢ scale_pos_weight = {scale_pos:.2f}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3) XGBoost Modelini EÄŸit\n",
    "# ----------------------------------------\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_clf.fit(X_train_meta, y_train_meta)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4) Test Verisi Ãœzerinde proba_meta Hesapla\n",
    "# ----------------------------------------\n",
    "proba_meta = xgb_clf.predict_proba(X_test_meta)[:, 1]\n",
    "feat_test[\"proba_meta\"] = proba_meta\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5) Threshold TaramasÄ±yla En Ä°yi EÅŸiÄŸi Bul\n",
    "# ----------------------------------------\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "thresholds = np.arange(0.1, 0.91, 0.05)\n",
    "results = []\n",
    "\n",
    "best_idxs = feat_test.groupby(\"question_id\")[\"proba_meta\"].idxmax()\n",
    "\n",
    "for t in thresholds:\n",
    "    pred_meta = np.zeros(len(feat_test), dtype=int)\n",
    "    best_probas = feat_test.loc[best_idxs, \"proba_meta\"]\n",
    "    valid_best = best_probas[best_probas > t].index\n",
    "    pred_meta[valid_best] = 1\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test_meta, pred_meta, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    results.append((t, precision, recall, f1))\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "# SonuÃ§larÄ± yazdÄ±r\n",
    "print(f\"\\nðŸ” Best threshold: {best_threshold:.2f} with F1-score: {best_f1:.3f}\\n\")\n",
    "print(\"Threshold | Precision | Recall | F1\")\n",
    "for r in results:\n",
    "    print(f\"{r[0]:.2f}       | {r[1]:.3f}     | {r[2]:.3f}  | {r[3]:.3f}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6) En Ä°yi Threshold ile Nihai Tahmin\n",
    "# ----------------------------------------\n",
    "feat_test[\"pred_meta\"] = 0\n",
    "best_probas = feat_test.loc[best_idxs, \"proba_meta\"]\n",
    "valid_best = best_probas[best_probas > best_threshold].index\n",
    "feat_test.loc[valid_best, \"pred_meta\"] = 1\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7) SonuÃ§larÄ± YazdÄ±r\n",
    "# ----------------------------------------\n",
    "print(\"\\nðŸ“Š Final Report (Threshold Applied):\")\n",
    "print(classification_report(y_test_meta, feat_test[\"pred_meta\"], digits=3))\n",
    "print(\"ðŸ”Ž Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_meta, feat_test[\"pred_meta\"]))\n",
    "\n",
    "print(X_train_meta.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
