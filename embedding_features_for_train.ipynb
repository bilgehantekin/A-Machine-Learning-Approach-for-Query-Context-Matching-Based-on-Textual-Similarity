{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Ham WikiQA verisini ve question_id’yi yükle\n",
    "df = pd.read_csv(\"wikiqa_train.csv\")\n",
    "# df sütunları: ['question_id', 'question', 'document_title', 'answer', 'label']\n",
    "\n",
    "# 2. İndex’i sıfırla ve sample alın (istersen tüm veri de olabilir)\n",
    "sample_df = df.reset_index(drop=True)  # tüm satırlar\n",
    "\n",
    "# 3. Sentence-BERT modelini yükle\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Metinleri listele\n",
    "questions = sample_df[\"question\"].tolist()\n",
    "answers   = sample_df[\"answer\"].tolist()\n",
    "\n",
    "# 5. Embedding’leri hesapla\n",
    "print(\"Embedding hesaplanıyor...\")\n",
    "q_embs = model.encode(questions, convert_to_numpy=True, show_progress_bar=True)\n",
    "a_embs = model.encode(answers,   convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# 6. Feature’ları hesapla\n",
    "print(\"Özellikler hesaplanıyor...\")\n",
    "cosine_sims    = []\n",
    "euclid_dists   = []\n",
    "dot_prods      = []\n",
    "l1_diffs       = []\n",
    "length_diffs   = []\n",
    "mean_diffs     = []\n",
    "max_diffs      = []\n",
    "\n",
    "for q_vec, a_vec, q_txt, a_txt in tqdm(zip(q_embs, a_embs, questions, answers), total=len(questions)):\n",
    "    cosine_sims.append(   cosine_similarity([q_vec], [a_vec])[0][0] )\n",
    "    euclid_dists.append(  euclidean(q_vec, a_vec) )\n",
    "    dot_prods.append(     np.dot(q_vec, a_vec) )\n",
    "    l1_diffs.append(      np.sum(np.abs(q_vec - a_vec)) )\n",
    "    length_diffs.append(  abs(len(q_txt) - len(a_txt)) )\n",
    "    mean_diffs.append(    abs(np.mean(q_vec) - np.mean(a_vec)) )\n",
    "    max_diffs.append(     abs(np.max(q_vec)  - np.max(a_vec)) )\n",
    "\n",
    "# 7. question_id ve tüm feature’ları bir araya getir\n",
    "features_df = pd.DataFrame({\n",
    "    \"question_id\":         sample_df[\"question_id\"],\n",
    "    \"cosine_similarity\":   cosine_sims,\n",
    "    \"euclidean_distance\":  euclid_dists,\n",
    "    \"dot_product\":         dot_prods,\n",
    "    \"l1_difference\":       l1_diffs,\n",
    "    \"length_difference\":   length_diffs,\n",
    "    \"mean_difference\":     mean_diffs,\n",
    "    \"max_difference\":      max_diffs,\n",
    "    \"label\":               sample_df[\"label\"]\n",
    "})\n",
    "\n",
    "# 8. Test/Train için ayrı isimle kaydet\n",
    "features_df.to_csv(\"advanced_embedding_features_train.csv\", index=False)\n",
    "print(\"✅ advanced_embedding_features_train.csv başarıyla oluşturuldu.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
